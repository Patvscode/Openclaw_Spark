# 2026-02-13

## Parallel Mini Benchmark (6x)
- OLLAMA_NUM_PARALLEL=6, fired 6 Mini (20B) tasks simultaneously
- Results: Math 36s, Code 45s, Summarize 47s, Creative 23s, Analysis 21s, FileOps 43s
- Total wall time: ~47s vs ~108s sequential = **2.3x throughput improvement**
- Solo baseline: 18s/task — parallel adds ~1.5-2.5x per-task overhead but massive total throughput gain
- During run: 25.4GB/120GB memory (21%), GPU utilization 79%

## Hardware Findings
- DGX Spark barely stressed at 6 parallel 20B models
- Tons of memory headroom — could run Bob (65GB) + 6 Minis (25GB) = 90GB, still 30GB free
- gpt-oss:20b is MoE: 20.9B total params, ~4-5B active/token — punches above weight

## Parallel Stress Tests

### Simple math tasks (identical difficulty):
| Parallel | Per-task range | Wall time | Throughput vs sequential |
|----------|---------------|-----------|------------------------|
| 1 (solo) | 18s | 18s | 1.0x |
| 6 | 21-47s | 47s | 2.3x |
| 8 (warm) | 9-36s | 36s | 4.0x ← best |
| 10 | 58-90s | 90s | 2.0x |

- 10-parallel test was cold GPU; 8-parallel was warm → huge difference
- Sweet spot: 8 parallel with warm model
- OLLAMA_NUM_PARALLEL currently set to 12, subagents maxConcurrent 12

### Real task: 8-file Python calculator app
**Minis (8 parallel, no coordination):**
- Wall time: ~130s
- Files actually written: 5/8 (calc.py, cli.py, validator.py MISSING)
- 3 Minis claimed success but didn't write files → tool-use reliability issue

**Bob solo (120B):**
- Wall time: 32s (suspiciously fast)
- Files written: 0/8 — empty directory
- Hallucinated completing the entire task

**Key finding:** Both local models have tool-use reliability problems. They claim success without executing file writes. 20B actually performed better (5/8 vs 0/8). Issue is likely Ollama tool-calling, not model intelligence.

**Next step:** Investigate tool-call failures, consider wrapper approach (models output code in response, external script writes files)

## Ollama Stability
- Ollama crashed/restarted during Bob's app benchmark (was restarted at 01:48 EST)
- This explains Bob's 0-file result — he literally didn't run
- Retrying Bob app benchmark with fresh warm-up and explicit file-write instructions
- May need to monitor Ollama stability under heavy parallel load

## Telegram Inline Buttons
- Pat requested inline button controls for benchmarks in Telegram
- Sent benchmark control panel with buttons: bench:minis-app, bench:bob-app, bench:compare, bench:stress-N
- TODO: build out more interactive controls

## Mini Swarm → Bob Review Pipeline (proposed)
- Break research into 6-8 subtasks → fire all Minis parallel (~45s)
- Bob reads all findings, synthesizes, fills gaps (~2 min)
- Total ~3 min vs 15+ min if Bob did it all alone

## Bob's First Research Output
- Bob already completed first task: self-improving-ai-architectures.md in findings/
- His autonomous worker cron (every 30 min) is working

## Sudo Access
- pmello has sudo for systemctl and sed (ollama service management)
- Not general sudo — journalctl/dmesg still blocked
