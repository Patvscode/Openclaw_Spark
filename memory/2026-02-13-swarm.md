# 2026-02-13 — Swarm Setup & Architecture

## Swarm Status
- 8 Mini agents registered: Alpha(1), Beta(2), Gamma(3), Delta(4), Echo(5), Foxtrot(6), Golf(7), Hotel(8)
- All use gpt-oss:20b, each has own workspace at /home/pmello/.openclaw/workspace-mini-N/
- Shared workspace: /home/pmello/.openclaw/workspace-swarm/
- All 8 completed onboarding: 7/8 logged memory, 5/8 built first tool, 0/8 posted status (reliability issue)
- Staggered cron jobs every 30 min (offset 4 min each) for self-learning loops
- Telegram commands registered: /alpha through /hotel, /bob, /swarm, /panel, /stocks

## Cron Job IDs (minis)
- mini-1 Alpha: cb569457 | mini-2 Beta: 11406af9 | mini-3 Gamma: 31e47577
- mini-4 Delta: 77147c39 | mini-5 Echo: 73ebd151 | mini-6 Foxtrot: 2b63d66f
- mini-7 Golf: bd115b46 | mini-8 Hotel: 6030952d

## Bob's Overnight Research (14 findings!)
- Self-improving AI architectures, 6-DOF arm survey, two-brain architectures
- Thor 6-DOF build guide, ROS2 integration, safety frameworks
- Benchmark/cost analysis, edge-cloud latency, dual-compute frameworks
- All in /home/pmello/.openclaw/workspace-bob/findings/

## Backup System
- scripts/backup-all.sh backs up all workspaces (swarm, minis, bob) to main git repo
- Pushed 41 files to GitHub (Patvscode/Openclaw_Spark)

## Spark App — Swarm Management Platform
- Architecture doc: /workspace-swarm/projects/spark-app/ARCHITECTURE.md
- Stack: Flask + SQLite + vanilla JS
- Each mini assigned a module (Alpha=skeleton, Beta=status API, etc.)
- Bob does integration/review
- Features: agent dashboard, task manager, findings browser, training data collector, chat, analytics

## Sesame AI Voice (in progress)
- Bob researching open-source Maya voice model
- Goal: voice-to-voice conversations with all agents
- Research task dispatched, waiting on findings

## OLLAMA_NUM_PARALLEL Status
- Currently set to 3 (safe for both 120B and 20B)
- Sweet spot for 20B-only: 8 parallel
- 120B crashes above 3 parallel (KV cache OOM)
- Need dynamic switching solution long-term

## Key Lessons
- 20B minis: fast but unreliable at tool use (file writing ~60-70% success rate)
- 120B Bob: slower but reliable, actually produces working code
- Mini swarm → Bob review is the right pipeline
- Warm model cache matters hugely for performance (cold: 60-90s, warm: 9-36s per task)
- OLLAMA_NUM_PARALLEL too high crashes 120B model loading
