# 2026-02-14 — Day 3

## Town Hall Group Chat — Lessons Learned
- Chat ID: -5195425739, all bots added with group activation set to "always"
- 20B minis can't sustain real multi-agent conversation — they parrot each other and stall
- Pat removed Spark from the group to stop burning Opus tokens on noise
- File-based async coordination (cron loops + comms/) works better for 20B models
- Bob-orchestrated Town Hall cron (reads statuses, synthesizes, decides) is the right approach
- Live Telegram group chat for minis is not viable with current model quality

## 20B Model Limitations Confirmed
- No native reasoning capability — "thinking" just produces leaked rambling
- Can't build on each other's ideas or have genuine debate
- Good at: file-based async tasks, cron loops with specific instructions, voting via markdown
- Bad at: live conversation, creative problem-solving, self-directed collaboration

## Vision Model Discussion
- Pat wants an Omni/vision model in the agent mix
- llava:latest already pulled in Ollama
- GPU memory: ~95GB used (20B=14GB + 120B=81GB), ~33GB free
- Options: LLaVA 13B (8GB), LLaVA 34B (20GB), or newer models
- Plan: dedicate an agent as "Eyes" for image analysis, screenshots, diagrams

## GPU Memory Snapshot
- gpt-oss:20b — 14GB, 100% GPU
- gpt-oss:120b-ctx131k — 81GB, 100% GPU
- ~33GB headroom for additional models

## Config Changes Made
- All mini SOUL.md files updated: Town Hall = always participate, other groups = only when relevant
- Group activation set to "always" for all bots in Town Hall
- Spark removed from Town Hall group (Pat's decision to save tokens)

## Evening — Major Restructure & Model Library Build
- **14 Ollama models now downloaded** including qwen3:8b/14b/32b, qwen3-coder, qwen3-vl:8b, deepseek-r1:14b, nomic-embed-text
- **All agents upgraded**: Alpha→qwen3:14b, Beta-Hotel→qwen3:8b (from gpt-oss:20b)
- **All 8 SOUL.md files rewritten** with unique Qwen3-optimized role personalities
- **Self-governance framework**: SWARM.md v2 at workspace-swarm/ with voting, escalation, self-improvement loop
- **AI-Scientist repo patched** for local Ollama — `_OLLAMA_ACTIVE` flag in llm.py, Python 3.12 venv working
- **Boot tests passed** on Alpha, Gamma, Delta, Beta — all agents boot on Qwen3, zero reasoning leakage
- **Git pushed** to `hierarchical-agent-restructure` branch

## Tool-Use Blocker (Critical)
- Qwen3 CAN produce tool_calls via raw Ollama API (curl test proved it)
- But OpenClaw agents describe work in text instead of invoking tools
- Web research confirms ecosystem-wide issues: Ollama #11135 (hallucinated calls), streaming bugs, 8B inconsistency
- This blocks ALL agent autonomy — agents can think but can't act
- Possible fixes: XML fallback parsing, model-specific workarounds, OpenClaw patch, or wait for upstream fixes

## Three Deployment Configs Defined
- Config A "Everyday" (~109GB): Bob + Alpha(14B) + 6 workers(8B) + embeddings
- Config B "Full Power" (~101GB): Bob + qwen3:32b + deepseek-r1:14b + vision + embeddings
- Config C "Swarm Blitz" (~77GB): Alpha(14B) + 8 workers(8B) + embeddings (no Bob)
