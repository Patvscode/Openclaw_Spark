# 2026-02-14 — Day 3

## Town Hall Group Chat — Lessons Learned
- Chat ID: -5195425739, all bots added with group activation set to "always"
- 20B minis can't sustain real multi-agent conversation — they parrot each other and stall
- Pat removed Spark from the group to stop burning Opus tokens on noise
- File-based async coordination (cron loops + comms/) works better for 20B models
- Bob-orchestrated Town Hall cron (reads statuses, synthesizes, decides) is the right approach
- Live Telegram group chat for minis is not viable with current model quality

## 20B Model Limitations Confirmed
- No native reasoning capability — "thinking" just produces leaked rambling
- Can't build on each other's ideas or have genuine debate
- Good at: file-based async tasks, cron loops with specific instructions, voting via markdown
- Bad at: live conversation, creative problem-solving, self-directed collaboration

## Vision Model Discussion
- Pat wants an Omni/vision model in the agent mix
- llava:latest already pulled in Ollama
- GPU memory: ~95GB used (20B=14GB + 120B=81GB), ~33GB free
- Options: LLaVA 13B (8GB), LLaVA 34B (20GB), or newer models
- Plan: dedicate an agent as "Eyes" for image analysis, screenshots, diagrams

## GPU Memory Snapshot
- gpt-oss:20b — 14GB, 100% GPU
- gpt-oss:120b-ctx131k — 81GB, 100% GPU
- ~33GB headroom for additional models

## Config Changes Made
- All mini SOUL.md files updated: Town Hall = always participate, other groups = only when relevant
- Group activation set to "always" for all bots in Town Hall
- Spark removed from Town Hall group (Pat's decision to save tokens)
